---
date: '2021-04-22'
slug: 'symbolic-logic'
title: 'Symbolic Logic'
subtitle: 'or Algebra meets Logic'
description: ''
excerpt: null
tags: ['React']
relatedPostsSlugs: []
---

In college, I double majored in Philosophy and Mathematics. A required class for both of those majors was one called Symbolic Logic, or often referred to as Propositional Logic. The course teaches you to break arguments down into an algebraic notation and follow a set of principles to come to logically sound conclusions.

I have found that as a software engineer I frequently use the principles this course taught me in my programming. I may not look at some code and specifically say out loud, "That's a _modus ponens_" or "That's a hypothetical syllogism", but I know they're there. <Marker content={`I have said, "I can use DeMorgan's Law here," many times.`} />

My hope with this post isn't to radically change your ability to code, but rather give you some vocabulary for discussing logic in your programs and more.

### Foundational knowledge

There are a few things you need to know before reading the rest of this post. I'm going to express all of these logical principles with pseudo-code as best as I can. This accomplishes two things (at least). First, it makes it easier for me to type (rather than using the formal symbols more commonly used in textbooks on the subject). Second, it is my hope that using a code-like syntax will help you relate the concepts to your coding work more easily, therefore improving the learning of the concepts.

In my pseudo-code, I will be using the traditional letters used in symbolic logic, `p` and `q`, as placeholders for propositions. You can think of them as variables in our logical equations. To the best of my knowledge, `p` was chosen as an abbreviation of "proposition", and then letters are chosen by alphabetical order. Just like real variable names, you can choose to replace them with something more meaningful if that helps you.

Here is a small legend of my pseudo-code:

- `p` or `q` represent propositions, or elements of an argument
- `=>` is used for "entails". It can also be read as "If `p`, then `q`"
- `---` is used to indicate the end of the original propositions. What follows are conclusions derived from those propositions.
- `!` is used for "negation"
- `&` is used for "and"
- `|` is used for "inclusive or"
- `^` is used for "exclusive or"
- `===` is used for "material equivalence"

Certain conclusions can only be derived from applying other logical principles. When a principle is applied, an abbreviation of the principle's name, as well as the line numbers of the propositions required to impart that principle, will be noted next to the conclusion.

### Rules of Inference

The first set of logical rules we are going to discuss can be categorized as "rules of inference". That is, from the information at hand, we can logically deduce a set of conclusions. This set of logical principles may be useful in debugging programs, as they will teach you to arrive at sound conclusions given the information you have. Let's get started.

#### _Modus Ponens_ - M.P.

_Modus ponens_ is the most foundational rule of inference we can learn. I would tell you what the Latin means, but honestly, I think it would only add confusion rather than clarity, so I'll leave you to read the [wiki on it](https://en.wikipedia.org/wiki/Modus_ponens) on your own. The rule reads as follows:

If `p`, then `q`. `p` is true, therefore `q`.

And in our symbolic logic format, it looks like:

```
1. p => q
2. p
---
3. q   1,2 M.P.
```

If one proposition entails another and the first proposition is true, we can conclude that the second proposition is true. We use this all of the time in programming:

```javascript
if (data) {
  doSomethingWith(data)
}
```

This principle is also used frequently when debugging code. If you do not have the result you would expect from a condition, then you must not have a truthful condition.

The opposite, if I have the result I expect, then I must have a truthful condition, **cannot** be logically deduced and is a common fallacy known as "affirming the consequent". The reason this fails is that there may be other propositions that entail `q` other than `p`. Be careful when you program in making this fallacy. Getting the right result doesn't necessarily guarantee it got there by the path you expected. Always verify.

#### _Modus Tollens_

Our next rule of inference is _modus tollens_, whose Latin meaning might also cause more confusion than clarity, [wiki here](https://en.wikipedia.org/wiki/Modus_tollens). It is closely related to _modus ponens_. It follows:

If `p`, then `q`. Not `q`, therefore not `p`.

And in symbolic form, reads as:

```
1. p => q
2. !q
---
3. !p   1,2 M.T.
```

I have always found _modus tollens_ fascinating. Heuristically, we would gravitate towards saying, "Not `p` entails not `q`", but this isn't quite true. Why? Because other elements of the universe can cause `q`. We only know with certainty that the truthful condition of `p` entails the consequent of `q`. Thus, we also know with certainty, that the absence of `q` ensures the absence of `p`.

In programming, if we know that we have written a condition correctly, and we do not get the desired result, than we can deduce we have not met our condition. Worse than not meeting the requirements our condition, is knowing we have not satisfied our condition and, yet, our desired result still occurs. That, my friends, is a bug.

#### Conjuction and Simplification

No more Latin principles. I promise. Our next rules can be considered partners, and therefore will be taught together.

Conjuction is the combining of two propositions: `p`, `q`, therefore `p & q`.

```
1. p
2. q
---
3. p & q   1,2 Con.
```

Simplification is taking a conjuction and reducing it to one of its propositions: `p & q`, therefore `p`.

```
1. p & q
---
2. p   1 Simp.
```

In programming, we create a number of conjunctions and simplifications all the time. A conjunction could be creating a condition based on two different values, and a simplification could be the destructuring of a key/value from an object.

#### Hypothetical Syllogism

This logical principle is sometimes known as "double _modus ponens_", you'll soon see why.

`p` entails `q` and `q` entails `r`. Therefore, `p` entails `r`.

```
1. p => q
2. q => r
---
3. p => r   1,2 H.S.
```

For me, hypothetical syllogism _just makes sense_, which has always made it a bit difficult to explain to others. Essentially, it's a chain of _modus ponens_, and removing the middle link in that chain.

It is closely related to the transitive property. For example, in math, if you had `x > y` and `y > z`, then you can infer that `x > z`.

In programming, correct usage of hypothetical syllogism may show you that you're able to reduce a few steps in a particular program, recognizing that one antecedent, `p` entails a further consequent, `r`.

#### Absorption

This one is probably the first oddball we're going to encounter and it might not be terribly useful for programming, though there might be times it is useful in debugging. Absorption goes as follows:

If `p`, then `q`. Therefore, if `p`, then `p & q`.

```
1. p => q
---
2. p => p & q   1 Abs.
```

The premise of this principle builds upon a conjunction. If a condition leads to a result, then it is true that having that condition means having both the condition and the result. Another way to think about this is, the condition doesn't _disappear_ because it has led to a result. It is still present, and therefore, can be combined with the result to make new inferences.

#### Disjunctive Syllogism

`p` (inclusive) or `q`. Not `p`. Therefore, `q`.

```
1. p | q
2. !p
---
3. q   1,2 D.S.
```

#### Constructive Dilemma

`p` entails `q`, and `r` entails `s`. `p | r`. Therefore, `q | s`.

```
1. (p => q) & (r => s)
2. p | r
---
3. q | s   1,2 C.D.
```

#### Addition

`p`, therefore `p | q`.

This one's odd, but useful for meeting the requirements for other principles. Essentially, if you have a proposition, then you have that proposition _or_ any other proposition in the universe.

### Rules of Replacement

The next set of priciples we will learn are known as "rules of replacement". These rules will teach us logically sound ways to swap one set of premises for another. These rules can often be applied when trying to improve the legibility or even the performance of some code.

#### Double Negation

`p === !!p`

#### Commutation

`p | q === q | p` as well as `p & q === q & p`

#### Tautology

This one is quite possibly my favorite.

`p === p | p` as well as `p === p & p`

#### Association

`(p | (q | r)) === ((p | q) | r)` as well as `(p & (q & r)) === ((p & q) & r)`

#### Transposition

`p => q === !q => !p`

#### Material Implication

`p => q === !p | q`

#### Exportation

`(p & q) => r === p => (q => r)`

#### Material Equivalence

`(p === q) === ((p => q) & (q => p))`

`(p === q) === ((p & q) | (!p & !q))`

#### Distribution

`(p & (q | r)) === ((p & q) | (p & r))`

`(p | (q & r)) === ((p | q) & (p | r))`

#### De Morgan's Theorems

`!(p & q) === (!p | !q)`

`!(p | q) === (!p & !q)`
